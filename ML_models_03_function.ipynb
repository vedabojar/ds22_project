{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f442f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, VotingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.neighbors\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import LinearSVR \n",
    "from sklearn import neighbors\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(df, target_col):\n",
    "    \n",
    "    # assuming your dataframe is named 'df' and our column we want to predict is 'Rating' column\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Splitting the df to train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Model 1 - Linear Regression\n",
    "\n",
    "    ## Errorif y_type in [\"binary\", \"multiclass\"]:  Because I tried to predict y = df[['Rating', 'Profit_inf']]at the same time. \n",
    "    #ValueError: continuous-multioutput is not supported\n",
    "\n",
    "    # scaling w RobustScaler object and fit to training data\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # apply the scaler to both the training and testing data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred =lr.predict(X_test_scaled)\n",
    "\n",
    "    # evaluate the model performance using mean absolute error and mean squared error and RMSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(mse)\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    lin_reg = (mae, mse, RMSE, R2)\n",
    "    \n",
    "    # Model 2 - SVR (Support Vector Machine Regressor)\n",
    "\n",
    "    ##SVR performs better on regression problems whereas SVM on classification problems. Therefore we continue with SVR \n",
    "\n",
    "    #Scaling the data for SVM model\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    #fitting the training data for SVM model\n",
    "    svm_reg= LinearSVR(epsilon=1.5)\n",
    "\n",
    "    svm_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = svm_reg.predict(X_test_scaled)\n",
    "\n",
    "    # Performance metrics for SVR\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(mse)\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    svr = (mae, mse, RMSE, R2)\n",
    "    \n",
    "    # Model 3 - Decision Trees\n",
    "\n",
    "    #Voting and Bagging regressors on Ensemble methods help the models to reduce overfitting therefore we apply with Decision Tree\n",
    "\n",
    "    # Define a decision tree model\n",
    "    dtree = DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "    dtree.fit(X_train, y_train) \n",
    "\n",
    "    # Define a bagging regressor with decision tree models\n",
    "    bagging_model = BaggingRegressor(base_estimator=dtree, n_estimators=10, random_state=42)\n",
    "\n",
    "    #Approach is to use the same training algorithm for every predictor and train them on different random subsets of the training set\n",
    "\n",
    "    # Define a voting regressor with decision tree models\n",
    "    voting_model = VotingRegressor([('tree1', dtree), ('tree2', dtree), ('tree3', dtree)])\n",
    "\n",
    "    # Fit the models on the training data\n",
    "    dtree.fit(X_train, y_train)\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred_dtree = dtree.predict(X_test)\n",
    "    y_pred_bagging = bagging_model.predict(X_test)\n",
    "    y_pred_voting = voting_model.predict(X_test)\n",
    "\n",
    "    # Calculate the mean squared error of the predictions\n",
    "    mse_dtree = mean_squared_error(y_test, y_pred_dtree)\n",
    "    mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
    "    mse_voting = mean_squared_error(y_test, y_pred_voting)\n",
    "\n",
    "    rmse_dtree = np.sqrt(mse_dtree)\n",
    "    rmse_bag= np.sqrt(mse_bagging)\n",
    "    rmse_voting = np.sqrt(mse_voting)\n",
    "\n",
    "    R2_dtree = r2_score(y_test, y_pred_dtree)\n",
    "    R2_bagging = r2_score(y_test, y_pred_bagging)\n",
    "    R2_voting = r2_score(y_test, y_pred_voting)\n",
    "\n",
    "    tree = (\"N/A\", mse_dtree, rmse_dtree, R2_dtree)\n",
    "    tree_bag = (\"N/A\", mse_bagging, rmse_bag, R2_bagging)\n",
    "    tree_vot = (\"N/A\", mse_voting, rmse_bag, R2_voting)\n",
    "\n",
    "    # Cross validation , cv on Decision tree model \n",
    "    \n",
    "    # Model 4 - Random Forest\n",
    "\n",
    "    # Initialize the model\n",
    "    rf = RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n",
    "\n",
    "    #training model to Rfor.\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # evaluate the model performance using mean absolute error and mean squared error and RMSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    rf = (mae, mse, rmse, r2)\n",
    "          \n",
    "    # Model 5 - K-nearest neighbors\n",
    "    \n",
    "    # Train the KNN model\n",
    "    k = 5\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors =k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    scaler=RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    #Model performance metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    knn = (mae, mse, rmse, r2)\n",
    "  
    "\n",
    "    models = lin_reg, svr, tree, tree_bag, tree_vot, rf, knn\n",
    "    # create a dictionary of data\n",
    "    headers = ['Model', 'Mae', 'Mse', 'RMSE', 'R2']\n",
    "    models_name = ['Linear Reg', 'SVR', 'Descion Tree', 'DT bag', 'DT vot', 'RF', 'KNN']\n",
    "\n",
    "    data = {headers[0]: [models_name[0], models_name[1], models_name[2], models_name[3], models_name[4], models_name[5], models_name[6]],\n",
    "            headers[1]: [models[0][0], models[1][0], models[2][0], models[3][0], models[4][0], models[5][0], models[6][0]],\n",
    "            headers[2]: [models[0][1], models[1][1], models[2][1], models[3][1], models[4][1], models[5][1], models[6][1]],\n",
    "            headers[3]: [models[0][2], models[1][2], models[2][2], models[3][2], models[4][2], models[5][2], models[6][2]],\n",
    "            headers[4]: [models[0][3], models[1][3], models[2][3], models[3][3], models[4][3], models[5][3], models[6][3]]}\n",
    "\n",
    "    # create a DataFrame from the dictionary\n",
    "    df_models = pd.DataFrame(data)\n",
    "    \n",
    "    return df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models and print result    \n",
    "df=pd.read_csv('../00_data/mvoies_processed_noTitle.csv')\n",
    "target_col = \"Rating\"\n",
    "\n",
    "models = compare_models(df, target_col)\n",
    "models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
