{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348ae723",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdefb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import cpi #library for inflation-data\n",
    "df = pd.read_csv('C:/Users/admin1/Documents/GitHub/ds22_project/data/movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2802e21",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6a2a6",
   "metadata": {},
   "source": [
    "#### 1.1 --- check_non_numeric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_non_numeric_values(df, column):\n",
    "    \"\"\"Function takes in dataset and column. No kreturn, Printing out found non numeric values in the column.\"\"\"\n",
    "\n",
    "    # convert column to numeric data type\n",
    "    numeric_col = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "    # get the non-numeric values and their counts\n",
    "    non_numeric_values = df[column][numeric_col.isna()].value_counts()\n",
    "\n",
    "    # check if there are any non-numeric values\n",
    "    if non_numeric_values.empty:\n",
    "        print(\"No non numeric values in that column.\")\n",
    "    else:\n",
    "        # create a table with non-numeric values and their counts\n",
    "        non_numeric_table = pd.DataFrame({'Non-Numeric Value': non_numeric_values.index,\n",
    "                                          'Count': non_numeric_values.values})\n",
    "\n",
    "        # display the table\n",
    "        print(non_numeric_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb15962",
   "metadata": {},
   "source": [
    "#### 1.2 --- one_hot_encoding_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function\n",
    "def one_hot_encoding_column(dataset, column, separator=\", \", prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Performs one-hot encoding on the specified column of the given dataset.\n",
    "    dataset: The dataset to be processed.\n",
    "    column: The name of the column to be one-hot encoded.\n",
    "    separator: The separator used in the values of the specified column. Defaults to \",\".\n",
    "    prefix: Optional string to be added in front of each new column name. Defaults to \"\".\n",
    "    returns: the new dataset with the specified column one-hot encoded.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Creating a list with all the values mentioned in the dataset\n",
    "    value_list = [values.split(separator) for values in dataset[column]]\n",
    "\n",
    "    # 2. Creating a set with value categories\n",
    "    unique_v = {value for values in value_list for value in values}\n",
    "\n",
    "    # 3. Performing one-hot encoding using get_dummies method\n",
    "    value_subtable = pd.get_dummies(dataset[column].str.split(separator, expand=True).stack()).reset_index(level=1, drop=True)\n",
    "    value_subtable = value_subtable.groupby(value_subtable.index).sum()\n",
    "\n",
    "    # 4. Adding the prefix to the column names\n",
    "    if prefix:\n",
    "        value_subtable.columns = [prefix + str(col) for col in value_subtable.columns]\n",
    "\n",
    "    # 5. Merging the subtable with the main dataset\n",
    "    dataset_processed = pd.merge(dataset, value_subtable, left_index=True, right_index=True, how='left')\n",
    "    dataset_processed.drop(columns=[column], inplace=True)\n",
    "\n",
    "    # 6. Returning the new dataset\n",
    "    return dataset_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7ca99",
   "metadata": {},
   "source": [
    "#### 1.3 --- convert_to_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all currency to USD and removing all commas.\n",
    "\n",
    "def convert_to_usd(amount):\n",
    "    amount.replace(' ', '')\n",
    "    amount.replace('\\xa0', '')\n",
    "    if amount.startswith('$'):\n",
    "        amount = amount.strip('$').replace(',', '')   # must remove commas\n",
    "        return float(amount)   # convert str into float\n",
    "    elif amount.startswith('€'):\n",
    "        # Exchange rate for EUR to USD\n",
    "        amount = amount.strip('€').replace(',', '')\n",
    "        return float(amount) * 1.06 \n",
    "    elif amount.startswith('¥'):\n",
    "        # Exchange rate for YEN to USD\n",
    "        amount = amount.strip('¥').replace(',', '')\n",
    "        return float(amount) * 0.0075\n",
    "    elif amount.startswith('₹'):\n",
    "        # Exchange rate for RPL to USD\n",
    "        amount = amount.strip('₹').replace(',', '')\n",
    "        return float(amount) * 0.012 \n",
    "    elif amount.startswith('SEK'):\n",
    "        # Exchange rate for SEK to USD\n",
    "        amount = amount.strip('SEK').replace(',', '')\n",
    "        return float(amount) * 0.094\n",
    "    elif amount.startswith('DKK'):\n",
    "        # Exchange rate for RPL to USD\n",
    "        amount = amount.strip('DKK').replace(',', '')\n",
    "        return float(amount) * 0.14\n",
    "    elif amount.startswith('£'):\n",
    "        # Exchange rate for RPL to USD\n",
    "        amount = amount.strip('£').replace(',', '')\n",
    "        return float(amount) * 1.21  \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bdb5a3",
   "metadata": {},
   "source": [
    "#### 1.4 --- one_hot_coding_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e060edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def one_hot_coding_binary(dataset, original_column, prefix, file_column, file_location, separator=\", \", num_categories=1, drop_original=True):\n",
    "    if num_categories not in range(1,5):\n",
    "        raise ValueError(\"num_categories must be between 1 and 4\")\n",
    "\n",
    "    for i in range(1, num_categories+1):\n",
    "        dataset[f\"{prefix}_no_{i}\"] = dataset[original_column].str.split(separator, expand=True)[i-1]\n",
    "\n",
    "    dataset_categories = pd.read_csv(file_location)\n",
    "\n",
    "    for i in range(1, num_categories+1):\n",
    "        replace = dataset[f\"{prefix}_no_{i}\"].isin(dataset_categories[file_column])\n",
    "        dataset[f\"{prefix}_no_{i}_binary\"] = replace.astype(int)\n",
    "\n",
    "    if drop_original:\n",
    "        dataset.drop(columns=[original_column], inplace=True)\n",
    "\n",
    "    if num_categories == 1:\n",
    "        dataset.drop(columns=[f\"{prefix}_no_1\"], inplace=True)\n",
    "        dataset.rename(columns={f\"{prefix}_no_1_binary\": f\"{prefix}\"}, inplace=True)\n",
    "    else:\n",
    "        for i in range(1, num_categories+1):\n",
    "            dataset.drop(columns=[f\"{prefix}_no_{i}\"], inplace=True)\n",
    "            dataset.rename(columns={f\"{prefix}_no_{i}_binary\": f\"{prefix}_{i}\"}, inplace=True)\n",
    "\n",
    "        if num_categories == 5:\n",
    "            dataset.rename(columns={f\"{prefix}_all_binary\": f\"{prefix}_all\"}, inplace=True)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6be68",
   "metadata": {},
   "source": [
    "# Dataprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103637ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85837db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf6779",
   "metadata": {},
   "source": [
    "#### Dataprocessing Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae29e8e",
   "metadata": {},
   "source": [
    "create a table / column / object / comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd15c09",
   "metadata": {},
   "source": [
    "### 1.Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d7750",
   "metadata": {},
   "source": [
    "#### 1.1Unqiue/ Dupclicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244489e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_values = df['Title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcbabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744dc7f",
   "metadata": {},
   "source": [
    "My first instict was to expect 2000 unique values for titles of movies.\n",
    "So I thought to just remove them from the dataset since I expect them to be duplicate data.\n",
    "But."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df.duplicated(['Title'], keep=False)].sort_values(by=['Title'])\n",
    "\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a60258",
   "metadata": {},
   "source": [
    "Looking at the duplicate movie titles we can quickly see that its totally diffrent movies that only share the title name and nothing else therefore no duplicate data and we can keep it.\n",
    "I do expect that we drop this column since we cant make in to numeric.\n",
    "Well, you could keep it and count the length of the title but I would say that shouldnt have an effect on the model and just be in the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d634b",
   "metadata": {},
   "source": [
    "### 2.Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bcebc7",
   "metadata": {},
   "source": [
    "Rating of the movie, the user rates 0-10 and this it the average of that voting with 1 decimal. This is our y, the data that we want to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46622b31",
   "metadata": {},
   "source": [
    "#### 2.1 Missing data\n",
    "According to the info-function, there is one movie that doesn´t have a value. We cant do more than just drop that one from the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Rating'])\n",
    "\n",
    "\n",
    "#A quick check to see that the row was removed from the dataset\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769a9de5",
   "metadata": {},
   "source": [
    "Since this is what our model is gonna predict, I dont want to do more here. The type is float64, which tells us that all values is numeric and can be decimal and since imdb is ratings from 0-10 with decimals this seems correct. One thing to consider would be to 10x all the values in ratings and convert the column to an int since that will be quicker to work with.\n",
    "Actually wann quick check that all the values is between 0 and 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4efcba8",
   "metadata": {},
   "source": [
    "#### 2.2 Check the data is within expected range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values are between 0 and 10 (inclusive)\n",
    "column_values = df['Rating']\n",
    "count = column_values.between(0, 10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b67d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b0189",
   "metadata": {},
   "source": [
    "Our orginial dataset consistet of 2000 rows and we dropped one with missing values so 1999 was what we expected and hoped for. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc68b96",
   "metadata": {},
   "source": [
    "### 3.Year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9301c30",
   "metadata": {},
   "source": [
    "#### 3.1 Check the data is within expected range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values are between 0 and 10 (inclusive)\n",
    "column_values = df['Year']\n",
    "count = column_values.between(2002, 2023).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39028f0d",
   "metadata": {},
   "source": [
    "The type of the column is int which make sense aswell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ebc71",
   "metadata": {},
   "source": [
    "### 4.Month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6787c99",
   "metadata": {},
   "source": [
    "#### 4.1 Unqiue/ Dupclicate values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a57851",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values = df['Month'].unique()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293b520a",
   "metadata": {},
   "source": [
    "Seeing two values that I didnt expect,  2014 and 2018. Start with checking number of times they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcea137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times a specific string value occurs in a column\n",
    "count = df['Month'].value_counts()['2014']\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times a specific string value occurs in a column\n",
    "count = df['Month'].value_counts()['2008']\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db774378",
   "metadata": {},
   "source": [
    "Since they just occurs one time each in the Month-column I suggest we drop them since 2/ 1999 rows one impact our size of dataset especcially much and not seeing it beeing the worth the time to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=df.loc[df['Month'] == '2014'].index)\n",
    "df = df.drop(index=df.loc[df['Month'] == '2008'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the rows have been dropped\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values = df['Month'].unique()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5002a679",
   "metadata": {},
   "source": [
    "#### 4.2 Converting non-numeric to numeric values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map months to integers\n",
    "month_to_int = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,\n",
    "                'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "\n",
    "# Apply the map() method to convert the values\n",
    "df['Month'] = df['Month'].map(month_to_int)\n",
    "\n",
    "# Convert the type of the column to int\n",
    "df['Month'] = df['Month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the month-values has been rplaced by 1-12 and the column converted to int\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values = df['Month'].unique()\n",
    "column_values.sort()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6dde0",
   "metadata": {},
   "source": [
    "### 5.Certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221126ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.1 Unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique values of a column\n",
    "unique_values = df['Certificate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e308438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each unique value in the column, including missing values\n",
    "value_counts = df['Certificate'].value_counts(dropna=False)\n",
    "\n",
    "# Print the value counts\n",
    "print(value_counts)\n",
    "\n",
    "# Calculate the sum of the counts and print the total\n",
    "total = value_counts.sum()\n",
    "print(f'Total: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3949b45c",
   "metadata": {},
   "source": [
    "A couple of things. Tree columns stand out.\n",
    "Not Rated     61   --- probably takes a while from a movie is realsed until it gets rated. Make sense that this mostly consists of movies from the past year\n",
    "NaN           32   --- not sure how to replace\n",
    "Unrated        6   --- not sure how to replace\n",
    "\n",
    "At this point Im not sure how to replace the missing values and w/ ca 100 rows w/ diffrent kind of missing values its a bit much to drop them.\n",
    "My conclusion is to drop the whole column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407917e",
   "metadata": {},
   "source": [
    "### 6.Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bdf4da",
   "metadata": {},
   "source": [
    "#### 6.1 Check non numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking non numeric values\n",
    "check_non_numeric_values(df, \"Runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7adde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=df.loc[df['Runtime'] == 'Unknown'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that the row has been dropped\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec1c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the type of the column to int\n",
    "df['Runtime'] = df['Runtime'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee85269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the type has been changed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef797e",
   "metadata": {},
   "source": [
    "check for outliers, since movies should maybe have a range from 30-250min isch.\n",
    "So if i found values >30 or over 300 min I can assumme that something is wrong and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4590d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values are between 0 and 10 (inclusive)\n",
    "column_values = df['Runtime']\n",
    "count = column_values.between(30, 300).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6710f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b4ed7",
   "metadata": {},
   "source": [
    "Seems all remaining rows has a value between 30-300min which is good news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1326d",
   "metadata": {},
   "source": [
    "### 7.Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function\n",
    "df = one_hot_coding_binary(df, \"Directors\", \"top_50_director\", \"Name\", \"C:/Users/admin1/Documents/GitHub/ds22_project/data/top_50_directors.csv\", num_categories=4, drop_original=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking sum of each row\n",
    "director_one = df['top_50_director_1'].sum()\n",
    "director_two = df['top_50_director_2'].sum()\n",
    "director_three = df['top_50_director_3'].sum()\n",
    "director_four = df['top_50_director_4'].sum()\n",
    "\n",
    "\n",
    "df_directors = pd.DataFrame({'director_one': [director_one], 'director_two': [director_two], 'director_three': [director_three], 'director_four': [director_four]})\n",
    "\n",
    "df_directors.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb9107",
   "metadata": {},
   "source": [
    "### 8.Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ad135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function\n",
    "df = one_hot_coding_binary(df, \"Stars\", \"top_1000_Stars\", \"Name\", \"C:/Users/admin1/Documents/GitHub/ds22_project/data/top_1000_actors.csv\", num_categories=4, drop_original=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df38a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b14356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf218d8",
   "metadata": {},
   "source": [
    "### 9.Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cbd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding the column Genre\n",
    "df = one_hot_encoding_column(df, \"Genre\", separator=\", \", prefix = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking new dataset\n",
    "df.info()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dace6cd",
   "metadata": {},
   "source": [
    "### 9.Filmning_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc171c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3669ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that `df` is your pandas DataFrame object\n",
    "column_values = df['Filming_location'].value_counts().sort_values(ascending=False)\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e903d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing 75 movies with Unknown filming_location. How can we replace them? and seeing 97 unique filming locations.\n",
    "#We we´re discussing if movies mostly are beeing done w/ green screen.\n",
    "#maybe remove the whole column?\n",
    "\n",
    "#one hot encoding the column Filming_location\n",
    "#df = one_hot_encoding_column(df, \"Filming_location\", separator=\", \", prefix = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267812b",
   "metadata": {},
   "source": [
    "### 11.Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809786d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d786cd9e",
   "metadata": {},
   "source": [
    "### 12.Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f2e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62ba9d4f",
   "metadata": {},
   "source": [
    "### 13.Country_of_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding the column Genre\n",
    "df = one_hot_encoding_column(df, \"Country_of_origin\", separator=\", \", prefix = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
