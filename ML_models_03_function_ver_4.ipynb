{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f442f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, VotingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.neighbors\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import LinearSVR \n",
    "from sklearn import neighbors\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(df, target_col):\n",
    "    \n",
    "    # assuming your dataframe is named 'df' and our column we want to predict is 'Rating' column\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Splitting the df to train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Model 1 - Linear Regression\n",
    "\n",
    "    ## Errorif y_type in [\"binary\", \"multiclass\"]:  Because I tried to predict y = df[['Rating', 'Profit_inf']]at the same time. \n",
    "    #ValueError: continuous-multioutput is not supported\n",
    "\n",
    "    # scaling w RobustScaler object and fit to training data\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # apply the scaler to both the training and testing data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred =lr.predict(X_test_scaled)\n",
    "\n",
    "    # evaluate the model performance using mean absolute error and mean squared error and RMSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(mse)\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    lin_reg = (mae, mse, RMSE, R2)\n",
    "    \n",
    "    # Model 2 - SVR (Support Vector Machine Regressor)\n",
    "\n",
    "    ##SVR performs better on regression problems whereas SVM on classification problems. Therfore we continue with SVR \n",
    "\n",
    "    #Scaling the data for SVM model\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    #fitting the training data for SVM model\n",
    "    svm_reg= LinearSVR(epsilon=1.5)\n",
    "\n",
    "    svm_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = svm_reg.predict(X_test_scaled)\n",
    "\n",
    "    # Performance metrics for SVR\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(mse)\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    svr = (mae, mse, RMSE, R2)\n",
    "    \n",
    "    # Model 3 - Decision Trees\n",
    "\n",
    "    #Voting and Bagging regressors on Ensemble methods help the models to reduce overfitting therefore we apply with Decision Tree\n",
    "\n",
    "    # Define a decision tree model\n",
    "    dtree = DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "    dtree.fit(X_train, y_train) \n",
    "\n",
    "    # Define a bagging regressor with decision tree models\n",
    "    bagging_model = BaggingRegressor(base_estimator=dtree, n_estimators=10, random_state=42)\n",
    "\n",
    "    #Approach is to use the same training algorithm for every predictor and train them on different random subsets of the training set\n",
    "\n",
    "    # Define a voting regressor with decision tree models\n",
    "    voting_model = VotingRegressor([('tree1', dtree), ('tree2', dtree), ('tree3', dtree)])\n",
    "\n",
    "    # Fit the models on the training data\n",
    "    dtree.fit(X_train, y_train)\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred_dtree = dtree.predict(X_test)\n",
    "    y_pred_bagging = bagging_model.predict(X_test)\n",
    "    y_pred_voting = voting_model.predict(X_test)\n",
    "    \n",
    "    mae_dtree = mean_absolute_error(y_test, y_pred_dtree)\n",
    "    mae_bagging = mean_absolute_error(y_test, y_pred_bagging)\n",
    "    mae_voting = mean_absolute_error(y_test, y_pred_voting)\n",
    "\n",
    "    # Calculate the mean squared error of the predictions\n",
    "    mse_dtree = mean_squared_error(y_test, y_pred_dtree)\n",
    "    mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
    "    mse_voting = mean_squared_error(y_test, y_pred_voting)\n",
    "\n",
    "    rmse_dtree = np.sqrt(mse_dtree)\n",
    "    rmse_bag= np.sqrt(mse_bagging)\n",
    "    rmse_voting = np.sqrt(mse_voting)\n",
    "\n",
    "    R2_dtree = r2_score(y_test, y_pred_dtree)\n",
    "    R2_bagging = r2_score(y_test, y_pred_bagging)\n",
    "    R2_voting = r2_score(y_test, y_pred_voting)\n",
    "\n",
    "    tree = (mae_dtree, mse_dtree, rmse_dtree, R2_dtree)\n",
    "    tree_bag = (mae_bagging, mse_bagging, rmse_bag, R2_bagging)\n",
    "    tree_vot = (mae_voting, mse_voting, rmse_bag, R2_voting)\n",
    "\n",
    "    # Cross validation , cv on Decision tree model \n",
    "    \n",
    "    # Model 4 - Random Forest\n",
    "\n",
    "    # Initialize the model\n",
    "    rf = RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n",
    "\n",
    "    #training model to Rfor.\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # evaluate the model performance using mean absolute error and mean squared error and RMSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    rf = (mae, mse, rmse, r2)\n",
    "          \n",
    "    # Model 5 - K-nearest neighbors\n",
    "    \n",
    "    # Train the KNN model\n",
    "    k = 5\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors =k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    scaler=RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    #Model performance metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    knn = (mae, mse, rmse, r2)\n",
    "\n",
    "    #if model performs good and generalises good , why negativ R2??\n",
    "    \n",
    "    # Model 6 - Lasso Regression\n",
    "    # Lasso regression can help with feature selection by shrinking the coefficients of less important features to zero.\n",
    "\n",
    "    # scaling the data\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # initialize lasso regression model\n",
    "    lasso = Lasso(alpha=0.1)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # make predictions on the test set\n",
    "    y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "    # evaluate the model performance using mean absolute error and mean squared error and RMSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(mse)\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    lasso_reg = (mae, mse, RMSE, R2)\n",
    "    \n",
    "    # Model 7 - Polynomial\n",
    "    # Drop target column in df\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Convert X to a numpy array before reshaping\n",
    "    X_array = X.values.reshape(-1, 1)\n",
    "\n",
    "    poly= PolynomialFeatures(degree=2, include_bias= False)\n",
    "\n",
    "    X_poly = poly.fit_transform(X_array)\n",
    "\n",
    "    #print(X_poly.shape)\n",
    "\n",
    "    #splitting train, test val_set:\n",
    "    # train set=0.8, test set=0.2, val set= 0.8*0.25= 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "    # scaling w RobustScaler object and fit only to training data\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "    # Apply scaler to training, validation, and test data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    lr.intercept_, lr.coef_ \n",
    "\n",
    "    y_pred_val = lr.predict(X_val_scaled)\n",
    "    y_pred_test = lr.predict(X_test_scaled)\n",
    "\n",
    "    #predictions on val set\n",
    "    mse = mean_squared_error(y_val, y_pred_val)\n",
    "    RMSE = np.sqrt(mse)\n",
    "\n",
    "    #print(\"Validation set MSE: {:.2f}\".format(mse))\n",
    "    #print(f'RMSE: {RMSE}')\n",
    "\n",
    "    #predictions on test set\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    RMSE = np.sqrt(mse)\n",
    "\n",
    "    #print(\"Test set MSE: {:.2f}\".format(mse))\n",
    "    #print(f'RMSE: {RMSE}')\n",
    "\n",
    "    # Visualising the Polynomial Regression: edit\n",
    "\n",
    "    # got error code \n",
    "    #plt.scatter(X_array, y, color = 'blue')\n",
    "\n",
    "    #plt.plot(X, lg.predict(poly.fit_transform(X)), color = 'violet')\n",
    "    #plt.title('Polynomial Regression')\n",
    "    #plt.xlabel('X')\n",
    "    #plt.ylabel('ploy_predicted')\n",
    "    \n",
    "    pol = (\"N/A\", mse, RMSE, \"N/A\")\n",
    "    \n",
    "\n",
    "    models = lin_reg, svr, tree, tree_bag, tree_vot, rf, knn, lasso_reg, pol\n",
    "    # create a dictionary of data\n",
    "    headers = ['Model', 'Mae', 'Mse', 'RMSE', 'R2']\n",
    "    models_name = ['Linear Reg', 'SVR', 'Descion Tree', 'DT bag', 'DT vot', 'RF', 'KNN', 'Lasso', 'Polynomial']\n",
    "\n",
    "    data = {headers[0]: [models_name[0], models_name[1], models_name[2], models_name[3], models_name[4], models_name[5], models_name[6], models_name[7], models_name[8]],\n",
    "            headers[1]: [models[0][0], models[1][0], models[2][0], models[3][0], models[4][0], models[5][0], models[6][0], models[7][0], models[8][0]],\n",
    "            headers[2]: [models[0][1], models[1][1], models[2][1], models[3][1], models[4][1], models[5][1], models[6][1], models[7][1], models[8][1]],\n",
    "            headers[3]: [models[0][2], models[1][2], models[2][2], models[3][2], models[4][2], models[5][2], models[6][2], models[7][2], models[8][2]],\n",
    "            headers[4]: [models[0][3], models[1][3], models[2][3], models[3][3], models[4][3], models[5][3], models[6][3], models[7][3], models[8][3]]}\n",
    "\n",
    "    # create a DataFrame from the dictionary\n",
    "    df_models = pd.DataFrame(data)\n",
    "    \n",
    "    return df_models\n",
    "\n",
    "# Compare models and print result    \n",
    "df=pd.read_csv('./data/mvoies_processed_noTitle.csv')\n",
    "target_col = \"Rating\"\n",
    "\n",
    "models = compare_models(df, target_col)\n",
    "models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./data/mvoies_processed_noTitle.csv')\n",
    "\n",
    "def drop_and_compare_single(df, prefixes, target_col):\n",
    "    for prefix in prefixes:\n",
    "        for col in df.columns:\n",
    "            if col.startswith(prefix):\n",
    "                df_drop = df.drop(col, axis=1)\n",
    "                print(\"Dropped column:\", col)\n",
    "                models = compare_models(df_drop, target_col=target_col)\n",
    "                print(models)\n",
    "\n",
    "def drop_and_compare_cluster(df, col_prefix, target_col):\n",
    "    cols_to_drop = [col for col in df.columns if col.startswith(col_prefix)]\n",
    "    df_drop = df.drop(cols_to_drop, axis=1)\n",
    "    print(\"Dropped columns:\", \"Starts with: \" + col_prefix)\n",
    "    models = compare_models(df_drop, target_col=target_col)\n",
    "    print(models)\n",
    "\n",
    "target_col = \"Rating\"\n",
    "\n",
    "# Dropping each column one by one and running the models\n",
    "drop_and_compare_single(df, ['Year', 'Month', 'Runtime', 'Budget_inf', 'Income_inf', 'Profit_inf', 'ROI_inf'], target_col)\n",
    "\n",
    "# Dropping all columns starting with prefix and running the models\n",
    "cols = ['cert', 'genre', 'contient', 'top_50_director', 'top_1000_Stars']\n",
    "for col in cols:\n",
    "    print(drop_and_compare_cluster(df, col, target_col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff28ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
