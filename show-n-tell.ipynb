{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348ae723",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdefb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import cpi #library for inflation-data\n",
    "df = pd.read_csv('C:/Users/admin1/Documents/GitHub/ds22_project/data/movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2802e21",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6a2a6",
   "metadata": {},
   "source": [
    "#### 1.1 --- check_non_numeric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_non_numeric_values(df, column):\n",
    "    \"\"\"Function takes in dataset and column. No kreturn, Printing out found non numeric values in the column.\"\"\"\n",
    "\n",
    "    # convert column to numeric data type\n",
    "    numeric_col = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "    # get the non-numeric values and their counts\n",
    "    non_numeric_values = df[column][numeric_col.isna()].value_counts()\n",
    "\n",
    "    # check if there are any non-numeric values\n",
    "    if non_numeric_values.empty:\n",
    "        print(\"No non numeric values in that column.\")\n",
    "    else:\n",
    "        # create a table with non-numeric values and their counts\n",
    "        non_numeric_table = pd.DataFrame({'Non-Numeric Value': non_numeric_values.index,\n",
    "                                          'Count': non_numeric_values.values})\n",
    "\n",
    "        # display the table\n",
    "        print(non_numeric_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe1cdd6",
   "metadata": {},
   "source": [
    "#### 1.2 --- get_mean_median_for_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b692099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_median_for_column(df, col_name):\n",
    "    '''\n",
    "    This function takes in a pandas dataframe and the name of a column in the dataframe,\n",
    "    and returns the mean and median of the numeric values in the column that are not equal to 0.\n",
    "    Non-numeric values are converted to 0 before calculating the mean and median.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas dataframe\n",
    "    - col_name: str, name of column to be processed\n",
    "    \n",
    "    Returns:\n",
    "    - tuple of two floats: mean and median of numeric values in the column that are not equal to 0\n",
    "    '''\n",
    "    # Convert non-numeric values to 0\n",
    "    df[col_name] = pd.to_numeric(df[col_name], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Get the non-zero numeric values in the column\n",
    "    non_zero_vals = df[col_name][df[col_name] != 0]\n",
    "    \n",
    "    # Calculate the mean and median of the non-zero values\n",
    "    col_mean = non_zero_vals.mean()\n",
    "    col_median = non_zero_vals.median()\n",
    "    \n",
    "    return col_mean, col_median\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f25faa",
   "metadata": {},
   "source": [
    "#### 1.3 --- replace_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_values(df, col_name, stat='mean'):\n",
    "    '''\n",
    "    This function takes in a pandas dataframe and the name of a column in the dataframe.\n",
    "    It drops all rows where the value of the column is 0, and replaces those values with either \n",
    "    the mean or median of the rest of the values in the column, as specified by the user.\n",
    "    It also replaces any NaN values in the column with the same statistic as the missing values.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas dataframe\n",
    "    - col_name: str, name of column to be processed\n",
    "    - stat: str, either 'mean' or 'median', determines which statistic to use\n",
    "    \n",
    "    Returns:\n",
    "    - df: pandas dataframe with modified column\n",
    "    '''\n",
    "    # Calculate the selected statistic of the non-zero/non-NaN values in the column\n",
    "    if stat == 'mean':\n",
    "        stat_val = np.nanmean(df[df[col_name].notnull() & (df[col_name] != 0)][col_name])\n",
    "    elif stat == 'median':\n",
    "        stat_val = np.nanmedian(df[df[col_name].notnull() & (df[col_name] != 0)][col_name])\n",
    "    else:\n",
    "        raise ValueError(\"stat must be either 'mean' or 'median'\")\n",
    "    \n",
    "    # Replace the missing values (0 or NaN) with the selected statistic\n",
    "    df.loc[(df[col_name] == 0) | (df[col_name].isnull()), col_name] = stat_val\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88597a83",
   "metadata": {},
   "source": [
    "#### 2.1 --- convert_to_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_usd(amount):\n",
    "    amount.replace(' ', '')\n",
    "    amount.replace('\\xa0', '')\n",
    "    if amount.startswith('$'):\n",
    "        amount = amount.strip('$').replace(',', '')   # must remove commas\n",
    "        return float(amount)   # convert str into float\n",
    "    elif amount.startswith('€'):\n",
    "        # Exchange rate for EUR to USD\n",
    "        amount = amount.strip('€').replace(',', '')\n",
    "        return float(amount) * 1.06 \n",
    "    elif amount.startswith('¥'):\n",
    "        # Exchange rate for YEN to USD\n",
    "        amount = amount.strip('¥').replace(',', '')\n",
    "        return float(amount) * 0.0075\n",
    "    elif amount.startswith('₹'):\n",
    "        # Exchange rate for RPL to USD\n",
    "        amount = amount.strip('₹').replace(',', '')\n",
    "        return float(amount) * 0.012 \n",
    "    elif amount.startswith('SEK'):\n",
    "        # Exchange rate for SEK to USD\n",
    "        amount = amount.strip('SEK').replace(',', '')\n",
    "        return float(amount) * 0.094\n",
    "    elif amount.startswith('DKK'):\n",
    "        # Exchange rate for RPL to USD\n",
    "        amount = amount.strip('DKK').replace(',', '')\n",
    "        return float(amount) * 0.14\n",
    "    elif amount.startswith('£'):\n",
    "        # Exchange rate for RPL to USD\n",
    "        amount = amount.strip('£').replace(',', '')\n",
    "        return float(amount) * 1.21  \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9fe460",
   "metadata": {},
   "source": [
    "#### 2.2 --- adjust_for_inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_inflation(df, column_name, year_column, new_column, drop_original=True):\n",
    "    data = {\n",
    "        \"1990\": 5.398,\n",
    "        \"1991\": 4.235,\n",
    "        \"1992\": 3.0288,\n",
    "        \"1993\": 2.9517,\n",
    "        \"1994\": 2.6074,\n",
    "        \"1995\": 2.8054,\n",
    "        \"1996\": 2.9312,\n",
    "        \"1997\": 2.3377,\n",
    "        \"1998\": 1.5523,\n",
    "        \"1999\": 2.188,\n",
    "        \"2000\": 3.3769,\n",
    "        \"2001\": 2.8262,\n",
    "        \"2002\": 1.586,\n",
    "        \"2003\": 2.2701,\n",
    "        \"2004\": 2.6772,\n",
    "        \"2005\": 3.3927,\n",
    "        \"2006\": 3.2259,\n",
    "        \"2007\": 2.8527,\n",
    "        \"2008\": 3.8391,\n",
    "        \"2009\": -0.3555,\n",
    "        \"2010\": 1.64,\n",
    "        \"2011\": 3.1568,\n",
    "        \"2012\": 2.0693,\n",
    "        \"2013\": 1.4648,\n",
    "        \"2014\": 1.6222,\n",
    "        \"2015\": 0.1186,\n",
    "        \"2016\": 1.2616,\n",
    "        \"2017\": 2.1301,\n",
    "        \"2018\": 2.4426,\n",
    "        \"2019\": 1.8122,\n",
    "        \"2020\": 1.2336,\n",
    "        \"2021\": 4.6979\n",
    "    }\n",
    "    \n",
    "    # Create a new column in the DataFrame to store the adjusted values\n",
    "    df[new_column] = 0\n",
    "\n",
    "    # Loop over the rows in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Get the year from the row\n",
    "        year = row[year_column]\n",
    "        # Skip the row if the value in the specified column is NaN\n",
    "        if pd.isna(row[column_name]):\n",
    "            continue\n",
    "        # Get the inflation rate for each year from the dictionary\n",
    "        inflation_rates = [data[str(yr)] for yr in range(year, 2022)]\n",
    "        # Calculate the total inflation factor by multiplying the inflation rates together\n",
    "        total_inflation_factor = 1\n",
    "        for rate in inflation_rates:\n",
    "            total_inflation_factor *= 1 + (rate / 100)\n",
    "        # Get the value from the specified column\n",
    "        value = row[column_name]\n",
    "        # Adjust the value for inflation using the total inflation factor\n",
    "        adjusted_value = value * total_inflation_factor\n",
    "        # Round the result to two decimal places and store it in the new column\n",
    "        df.at[index, new_column] = round(adjusted_value, 2)\n",
    "\n",
    "    # Drop the original column if specified\n",
    "    if drop_original:\n",
    "        df = df.drop(columns=[column_name])\n",
    "\n",
    "    # Return the DataFrame with the adjusted values\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a50d56",
   "metadata": {},
   "source": [
    "#### 3.1 --- adjust_for_inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_column(dataset, column, separator=\", \", prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Performs one-hot encoding on the specified column of the given dataset.\n",
    "    dataset: The dataset to be processed.\n",
    "    column: The name of the column to be one-hot encoded.\n",
    "    separator: The separator used in the values of the specified column. Defaults to \",\".\n",
    "    prefix: Optional string to be added in front of each new column name. Defaults to \"\".\n",
    "    returns: the new dataset with the specified column one-hot encoded.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Creating a list with all the values mentioned in the dataset\n",
    "    value_list = [values.split(separator) for values in dataset[column]]\n",
    "\n",
    "    # 2. Creating a set with value categories\n",
    "    unique_v = {value for values in value_list for value in values}\n",
    "\n",
    "    # 3. Performing one-hot encoding using get_dummies method\n",
    "    value_subtable = pd.get_dummies(dataset[column].str.split(separator, expand=True).stack()).reset_index(level=1, drop=True)\n",
    "    value_subtable = value_subtable.groupby(value_subtable.index).sum()\n",
    "\n",
    "    # 4. Adding the prefix to the column names\n",
    "    if prefix:\n",
    "        value_subtable.columns = [prefix + str(col) for col in value_subtable.columns]\n",
    "\n",
    "    # 5. Merging the subtable with the main dataset\n",
    "    dataset_processed = pd.merge(dataset, value_subtable, left_index=True, right_index=True, how='left')\n",
    "    dataset_processed.drop(columns=[column], inplace=True)\n",
    "\n",
    "    # 6. Returning the new dataset\n",
    "    return dataset_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aedcc6a",
   "metadata": {},
   "source": [
    "#### 3.2 --- one_hot_coding_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_coding_binary(dataset, original_column, prefix, file_column, file_location, separator=\", \", num_categories=1, drop_original=True):\n",
    "    if num_categories not in range(1,5):\n",
    "        raise ValueError(\"num_categories must be between 1 and 4\")\n",
    "\n",
    "    for i in range(1, num_categories+1):\n",
    "        dataset[f\"{prefix}_no_{i}\"] = dataset[original_column].str.split(separator, expand=True)[i-1]\n",
    "\n",
    "    dataset_categories = pd.read_csv(file_location)\n",
    "\n",
    "    for i in range(1, num_categories+1):\n",
    "        replace = dataset[f\"{prefix}_no_{i}\"].isin(dataset_categories[file_column])\n",
    "        dataset[f\"{prefix}_no_{i}_binary\"] = replace.astype(int)\n",
    "\n",
    "    if drop_original:\n",
    "        dataset.drop(columns=[original_column], inplace=True)\n",
    "\n",
    "    if num_categories == 1:\n",
    "        dataset.drop(columns=[f\"{prefix}_no_1\"], inplace=True)\n",
    "        dataset.rename(columns={f\"{prefix}_no_1_binary\": f\"{prefix}\"}, inplace=True)\n",
    "    else:\n",
    "        for i in range(1, num_categories+1):\n",
    "            dataset.drop(columns=[f\"{prefix}_no_{i}\"], inplace=True)\n",
    "            dataset.rename(columns={f\"{prefix}_no_{i}_binary\": f\"{prefix}_{i}\"}, inplace=True)\n",
    "\n",
    "        if num_categories == 5:\n",
    "            dataset.rename(columns={f\"{prefix}_all_binary\": f\"{prefix}_all\"}, inplace=True)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6be68",
   "metadata": {},
   "source": [
    "# Dataprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103637ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85837db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd15c09",
   "metadata": {},
   "source": [
    "### 1.Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d7750",
   "metadata": {},
   "source": [
    "#### 1.1Unqiue/ Dupclicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244489e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_values = df['Title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcbabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744dc7f",
   "metadata": {},
   "source": [
    "My first instict was to expect 2000 unique values for titles of movies.\n",
    "So I thought to just remove them from the dataset since I expect them to be duplicate data.\n",
    "But."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df.duplicated(['Title'], keep=False)].sort_values(by=['Title'])\n",
    "\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a60258",
   "metadata": {},
   "source": [
    "Looking at the duplicate movie titles we can quickly see that its totally diffrent movies that only share the title name and nothing else therefore no duplicate data and we can keep it.\n",
    "I do expect that we drop this column since we cant make in to numeric.\n",
    "Well, you could keep it and count the length of the title but I would say that shouldnt have an effect on the model and just be in the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d634b",
   "metadata": {},
   "source": [
    "### 2.Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bcebc7",
   "metadata": {},
   "source": [
    "Rating of the movie, the user rates 0-10 and this it the average of that voting with 1 decimal. This is our y, the data that we want to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46622b31",
   "metadata": {},
   "source": [
    "#### 2.1 Missing data\n",
    "According to the info-function, there is one movie that doesn´t have a value. We cant do more than just drop that one from the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Rating'])\n",
    "\n",
    "\n",
    "#A quick check to see that the row was removed from the dataset\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769a9de5",
   "metadata": {},
   "source": [
    "Since this is what our model is gonna predict, I dont want to do more here. The type is float64, which tells us that all values is numeric and can be decimal and since imdb is ratings from 0-10 with decimals this seems correct. One thing to consider would be to 10x all the values in ratings and convert the column to an int since that will be quicker to work with.\n",
    "Actually wann quick check that all the values is between 0 and 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4efcba8",
   "metadata": {},
   "source": [
    "#### 2.2 Check the data is within expected range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values are between 0 and 10 (inclusive)\n",
    "column_values = df['Rating']\n",
    "count = column_values.between(0, 10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b67d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b0189",
   "metadata": {},
   "source": [
    "Our orginial dataset consistet of 2000 rows and we dropped one with missing values so 1999 was what we expected and hoped for. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc68b96",
   "metadata": {},
   "source": [
    "### 3.Year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9301c30",
   "metadata": {},
   "source": [
    "#### 3.1 Check the data is within expected range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values are between 0 and 10 (inclusive)\n",
    "column_values = df['Year']\n",
    "count = column_values.between(2002, 2023).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39028f0d",
   "metadata": {},
   "source": [
    "The type of the column is int which make sense aswell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ebc71",
   "metadata": {},
   "source": [
    "### 4.Month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6787c99",
   "metadata": {},
   "source": [
    "#### 4.1 Unqiue/ Dupclicate values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a57851",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values = df['Month'].unique()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293b520a",
   "metadata": {},
   "source": [
    "Seeing two values that I didnt expect,  2014 and 2018. Start with checking number of times they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcea137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times a specific string value occurs in a column\n",
    "count = df['Month'].value_counts()['2014']\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times a specific string value occurs in a column\n",
    "count = df['Month'].value_counts()['2008']\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db774378",
   "metadata": {},
   "source": [
    "Since they just occurs one time each in the Month-column I suggest we drop them since 2/ 1999 rows one impact our size of dataset especcially much and not seeing it beeing the worth the time to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=df.loc[df['Month'] == '2014'].index)\n",
    "df = df.drop(index=df.loc[df['Month'] == '2008'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the rows have been dropped\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values = df['Month'].unique()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5002a679",
   "metadata": {},
   "source": [
    "#### 4.2 Converting non-numeric to numeric values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map months to integers\n",
    "month_to_int = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,\n",
    "                'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "\n",
    "# Apply the map() method to convert the values\n",
    "df['Month'] = df['Month'].map(month_to_int)\n",
    "\n",
    "# Convert the type of the column to int\n",
    "df['Month'] = df['Month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the month-values has been rplaced by 1-12 and the column converted to int\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values = df['Month'].unique()\n",
    "column_values.sort()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6dde0",
   "metadata": {},
   "source": [
    "### 5.Certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221126ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.1 Unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique values of a column\n",
    "unique_values = df['Certificate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e308438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each unique value in the column, including missing values\n",
    "value_counts = df['Certificate'].value_counts(dropna=False)\n",
    "\n",
    "# Print the value counts\n",
    "print(value_counts)\n",
    "\n",
    "# Calculate the sum of the counts and print the total\n",
    "total = value_counts.sum()\n",
    "print(f'Total: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3949b45c",
   "metadata": {},
   "source": [
    "A couple of things. Tree columns stand out.\n",
    "Not Rated     61   --- probably takes a while from a movie is realsed until it gets rated. Make sense that this mostly consists of movies from the past year\n",
    "NaN           32   --- not sure how to replace\n",
    "Unrated        6   --- not sure how to replace\n",
    "\n",
    "At this point Im not sure how to replace the missing values and w/ ca 100 rows w/ diffrent kind of missing values its a bit much to drop them.\n",
    "My conclusion is to drop the whole column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407917e",
   "metadata": {},
   "source": [
    "### 6.Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bdf4da",
   "metadata": {},
   "source": [
    "#### 6.1 Check non numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking non numeric values\n",
    "check_non_numeric_values(df, \"Runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7adde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=df.loc[df['Runtime'] == 'Unknown'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that the row has been dropped\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec1c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the type of the column to int\n",
    "df['Runtime'] = df['Runtime'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee85269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the type has been changed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef797e",
   "metadata": {},
   "source": [
    "check for outliers, since movies should maybe have a range from 30-250min isch.\n",
    "So if i found values >30 or over 300 min I can assumme that something is wrong and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4590d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values are between 0 and 10 (inclusive)\n",
    "column_values = df['Runtime']\n",
    "count = column_values.between(30, 300).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6710f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b4ed7",
   "metadata": {},
   "source": [
    "Seems all remaining rows has a value between 30-300min which is good news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1326d",
   "metadata": {},
   "source": [
    "### 7.Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function\n",
    "df = one_hot_coding_binary(df, \"Directors\", \"top_50_director\", \"Name\", \"C:/Users/admin1/Documents/GitHub/ds22_project/data/top_50_directors.csv\", num_categories=4, drop_original=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking sum of each row\n",
    "director_one = df['top_50_director_1'].sum()\n",
    "director_two = df['top_50_director_2'].sum()\n",
    "director_three = df['top_50_director_3'].sum()\n",
    "director_four = df['top_50_director_4'].sum()\n",
    "\n",
    "\n",
    "df_directors = pd.DataFrame({'director_one': [director_one], 'director_two': [director_two], 'director_three': [director_three], 'director_four': [director_four]})\n",
    "\n",
    "df_directors.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb9107",
   "metadata": {},
   "source": [
    "### 8.Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ad135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function\n",
    "df = one_hot_coding_binary(df, \"Stars\", \"top_1000_Stars\", \"Name\", \"C:/Users/admin1/Documents/GitHub/ds22_project/data/top_1000_actors.csv\", num_categories=4, drop_original=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df38a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b14356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf218d8",
   "metadata": {},
   "source": [
    "### 9.Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cbd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding the column Genre\n",
    "df = one_hot_encoding_column(df, \"Genre\", separator=\", \", prefix = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking new dataset\n",
    "df.info()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dace6cd",
   "metadata": {},
   "source": [
    "### 10.Filmning_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc171c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3669ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that `df` is your pandas DataFrame object\n",
    "column_values = df['Filming_location'].value_counts().sort_values(ascending=False)\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e903d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing 75 movies with Unknown filming_location. How can we replace them? and seeing 97 unique filming locations.\n",
    "#We we´re discussing if movies mostly are beeing done w/ green screen.\n",
    "#maybe remove the whole column?\n",
    "\n",
    "#one hot encoding the column Filming_location\n",
    "#df = one_hot_encoding_column(df, \"Filming_location\", separator=\", \", prefix = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267812b",
   "metadata": {},
   "source": [
    "### 11.Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a48e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1 convert to USD and strip of non numeric characters\n",
    "df['Budget'] = df['Budget'].apply(convert_to_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the change\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db418d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 --- calc with inflation\n",
    "# Call the function to get the inflation-adjusted values for the \"value\" column\n",
    "df = adjust_for_inflation(df, \"Budget\", \"Year\", \"Budget_inf\", drop_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e29fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the change\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 check the mean and median of the column /value of 0 is not a part of the calculation\n",
    "get_mean_median_for_column(df, \"Budget_inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde03983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.4 replace missing values w/ mean or median\n",
    "df = replace_missing_values(df, \"Budget_inf\", stat='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77984524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f783150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ede9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786cd9e",
   "metadata": {},
   "source": [
    "### 12.Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f2e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcdc9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1 convert to USD and strip of non numeric characters\n",
    "df['Income'] = df['Income'].apply(convert_to_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75641e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 --- calc with inflation\n",
    "# Call the function to get the inflation-adjusted values for the \"value\" column\n",
    "df = adjust_for_inflation(df, \"Income\", \"Year\", \"Income_inf\", drop_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd83c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 check the mean and median of the column\n",
    "get_mean_median_for_column(df, \"Income_inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.4 replace missing values w/ mean or median\n",
    "df = replace_missing_values(df, \"Income_inf\", stat='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba9d4f",
   "metadata": {},
   "source": [
    "### 13.Country_of_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding the column Genre\n",
    "df = one_hot_encoding_column(df, \"Country_of_origin\", separator=\", \", prefix = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
