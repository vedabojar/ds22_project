{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348ae723",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdefb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('C:/Users/admin1/Documents/GitHub/ds22_project/data/movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2802e21",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6a2a6",
   "metadata": {},
   "source": [
    "#### 1.1 --- check_non_numeric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_non_numeric_values(df, column):\n",
    "    \"\"\"Function takes in dataset and column. No kreturn, Printing out found non numeric values in the column.\"\"\"\n",
    "\n",
    "    # convert column to numeric data type\n",
    "    numeric_col = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "    # get the non-numeric values and their counts\n",
    "    non_numeric_values = df[column][numeric_col.isna()].value_counts()\n",
    "\n",
    "    # check if there are any non-numeric values\n",
    "    if non_numeric_values.empty:\n",
    "        print(\"No non numeric values in that column.\")\n",
    "    else:\n",
    "        # create a table with non-numeric values and their counts\n",
    "        non_numeric_table = pd.DataFrame({'Non-Numeric Value': non_numeric_values.index,\n",
    "                                          'Count': non_numeric_values.values})\n",
    "\n",
    "        # display the table\n",
    "        print(non_numeric_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe1cdd6",
   "metadata": {},
   "source": [
    "#### 1.2 --- get_mean_median_for_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b692099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_median_for_column(df, col_name):\n",
    "    '''\n",
    "    This function takes in a pandas dataframe and the name of a column in the dataframe,\n",
    "    and returns the mean and median of the numeric values in the column that are not equal to 0.\n",
    "    Non-numeric values are converted to 0 before calculating the mean and median.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas dataframe\n",
    "    - col_name: str, name of column to be processed\n",
    "    \n",
    "    Returns:\n",
    "    - tuple of two floats: mean and median of numeric values in the column that are not equal to 0\n",
    "    '''\n",
    "    # Convert non-numeric values to 0\n",
    "    df[col_name] = pd.to_numeric(df[col_name], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Get the non-zero numeric values in the column\n",
    "    non_zero_vals = df[col_name][df[col_name] != 0]\n",
    "    \n",
    "    # Calculate the mean and median of the non-zero values\n",
    "    col_mean = non_zero_vals.mean()\n",
    "    col_median = non_zero_vals.median()\n",
    "    \n",
    "    return col_mean, col_median\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f25faa",
   "metadata": {},
   "source": [
    "#### 1.3 --- replace_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_values(df, col_name, stat='mean'):\n",
    "    '''\n",
    "    This function takes in a pandas dataframe and the name of a column in the dataframe.\n",
    "    It drops all rows where the value of the column is 0, and replaces those values with either \n",
    "    the mean or median of the rest of the values in the column, as specified by the user.\n",
    "    It also replaces any NaN values in the column with the same statistic as the missing values.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas dataframe\n",
    "    - col_name: str, name of column to be processed\n",
    "    - stat: str, either 'mean' or 'median', determines which statistic to use\n",
    "    \n",
    "    Returns:\n",
    "    - df: pandas dataframe with modified column\n",
    "    '''\n",
    "    # Calculate the selected statistic of the non-zero/non-NaN values in the column\n",
    "    if stat == 'mean':\n",
    "        stat_val = np.nanmean(df[df[col_name].notnull() & (df[col_name] != 0)][col_name])\n",
    "    elif stat == 'median':\n",
    "        stat_val = np.nanmedian(df[df[col_name].notnull() & (df[col_name] != 0)][col_name])\n",
    "    else:\n",
    "        raise ValueError(\"stat must be either 'mean' or 'median'\")\n",
    "    \n",
    "    # Replace the missing values (0 or NaN) with the selected statistic\n",
    "    df.loc[(df[col_name] == 0) | (df[col_name].isnull()), col_name] = stat_val\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88597a83",
   "metadata": {},
   "source": [
    "#### 2.1 --- convert_to_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_usd(amount):\n",
    "    amount.replace(' ', '')\n",
    "    amount.replace('\\xa0', '')\n",
    "    if amount.startswith('$'):\n",
    "        amount = amount.strip('$').replace(',', '')   # must remove commas\n",
    "        return float(amount)   # convert str into float\n",
    "    elif amount.startswith('€'):\n",
    "        # Exchange rate for EUR to USD\n",
    "        amount = amount.strip('€').replace(',', '')\n",
    "        return float(amount) * 1.06 \n",
    "    elif amount.startswith('¥'):\n",
    "        # Exchange rate for YEN to USD\n",
    "        amount = amount.strip('¥').replace(',', '')\n",
    "        return float(amount) * 0.0075\n",
    "    elif amount.startswith('₹'):\n",
    "        # Exchange rate for RPL to USD\n",
    "        amount = amount.strip('₹').replace(',', '')\n",
    "        return float(amount) * 0.012 \n",
    "    elif amount.startswith('SEK'):\n",
    "        # Exchange rate for SEK to USD\n",
    "        amount = amount.strip('SEK').replace(',', '')\n",
    "        return float(amount) * 0.094\n",
    "    elif amount.startswith('DKK'):\n",
    "        # Exchange rate for RPL to USD\n",
    "        amount = amount.strip('DKK').replace(',', '')\n",
    "        return float(amount) * 0.14\n",
    "    elif amount.startswith('£'):\n",
    "        # Exchange rate for RPL to USD\n",
    "        amount = amount.strip('£').replace(',', '')\n",
    "        return float(amount) * 1.21  \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9fe460",
   "metadata": {},
   "source": [
    "#### 2.2 --- adjust_for_inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_for_inflation(df, column_name, year_column, new_column, drop_original=True):\n",
    "    data = {\n",
    "        \"1990\": 5.398,\n",
    "        \"1991\": 4.235,\n",
    "        \"1992\": 3.0288,\n",
    "        \"1993\": 2.9517,\n",
    "        \"1994\": 2.6074,\n",
    "        \"1995\": 2.8054,\n",
    "        \"1996\": 2.9312,\n",
    "        \"1997\": 2.3377,\n",
    "        \"1998\": 1.5523,\n",
    "        \"1999\": 2.188,\n",
    "        \"2000\": 3.3769,\n",
    "        \"2001\": 2.8262,\n",
    "        \"2002\": 1.586,\n",
    "        \"2003\": 2.2701,\n",
    "        \"2004\": 2.6772,\n",
    "        \"2005\": 3.3927,\n",
    "        \"2006\": 3.2259,\n",
    "        \"2007\": 2.8527,\n",
    "        \"2008\": 3.8391,\n",
    "        \"2009\": -0.3555,\n",
    "        \"2010\": 1.64,\n",
    "        \"2011\": 3.1568,\n",
    "        \"2012\": 2.0693,\n",
    "        \"2013\": 1.4648,\n",
    "        \"2014\": 1.6222,\n",
    "        \"2015\": 0.1186,\n",
    "        \"2016\": 1.2616,\n",
    "        \"2017\": 2.1301,\n",
    "        \"2018\": 2.4426,\n",
    "        \"2019\": 1.8122,\n",
    "        \"2020\": 1.2336,\n",
    "        \"2021\": 4.6979\n",
    "    }\n",
    "    \n",
    "    # Create a new column in the DataFrame to store the adjusted values\n",
    "    df[new_column] = 0\n",
    "\n",
    "    # Loop over the rows in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Get the year from the row\n",
    "        year = row[year_column]\n",
    "        # Skip the row if the value in the specified column is NaN\n",
    "        if pd.isna(row[column_name]):\n",
    "            continue\n",
    "        # Get the inflation rate for each year from the dictionary\n",
    "        inflation_rates = [data[str(yr)] for yr in range(year, 2022)]\n",
    "        # Calculate the total inflation factor by multiplying the inflation rates together\n",
    "        total_inflation_factor = 1\n",
    "        for rate in inflation_rates:\n",
    "            total_inflation_factor *= 1 + (rate / 100)\n",
    "        # Get the value from the specified column\n",
    "        value = row[column_name]\n",
    "        # Adjust the value for inflation using the total inflation factor\n",
    "        adjusted_value = value * total_inflation_factor\n",
    "        # Round the result to two decimal places and store it in the new column\n",
    "        df.at[index, new_column] = round(adjusted_value, 2)\n",
    "\n",
    "    # Drop the original column if specified\n",
    "    if drop_original:\n",
    "        df = df.drop(columns=[column_name])\n",
    "\n",
    "    # Return the DataFrame with the adjusted values\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a50d56",
   "metadata": {},
   "source": [
    "#### 3.1 --- one_hot_encoding_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_column(dataset, column, separator=\", \", prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Performs one-hot encoding on the specified column of the given dataset.\n",
    "    dataset: The dataset to be processed.\n",
    "    column: The name of the column to be one-hot encoded.\n",
    "    separator: The separator used in the values of the specified column. Defaults to \",\".\n",
    "    prefix: Optional string to be added in front of each new column name. Defaults to \"\".\n",
    "    returns: the new dataset with the specified column one-hot encoded.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Creating a list with all the values mentioned in the dataset\n",
    "    value_list = [values.split(separator) for values in dataset[column]]\n",
    "\n",
    "    # 2. Creating a set with value categories\n",
    "    unique_v = {value for values in value_list for value in values}\n",
    "\n",
    "    # 3. Performing one-hot encoding using get_dummies method\n",
    "    value_subtable = pd.get_dummies(dataset[column].str.split(separator, expand=True).stack()).reset_index(level=1, drop=True)\n",
    "    value_subtable = value_subtable.groupby(value_subtable.index).sum()\n",
    "\n",
    "    # 4. Adding the prefix to the column names\n",
    "    if prefix:\n",
    "        value_subtable.columns = [prefix + str(col) for col in value_subtable.columns]\n",
    "\n",
    "    # 5. Merging the subtable with the main dataset\n",
    "    dataset_processed = pd.merge(dataset, value_subtable, left_index=True, right_index=True, how='left')\n",
    "    dataset_processed.drop(columns=[column], inplace=True)\n",
    "\n",
    "    # 6. Returning the new dataset\n",
    "    return dataset_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aedcc6a",
   "metadata": {},
   "source": [
    "#### 3.2 --- one_hot_coding_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_coding_binary(dataset, original_column, prefix, file_column, file_location, separator=\", \", num_categories=1, drop_original=True):\n",
    "    if num_categories not in range(1,5):\n",
    "        raise ValueError(\"num_categories must be between 1 and 4\")\n",
    "\n",
    "    for i in range(1, num_categories+1):\n",
    "        dataset[f\"{prefix}_no_{i}\"] = dataset[original_column].str.split(separator, expand=True)[i-1]\n",
    "\n",
    "    dataset_categories = pd.read_csv(file_location)\n",
    "\n",
    "    for i in range(1, num_categories+1):\n",
    "        replace = dataset[f\"{prefix}_no_{i}\"].isin(dataset_categories[file_column])\n",
    "        dataset[f\"{prefix}_no_{i}_binary\"] = replace.astype(int)\n",
    "\n",
    "    if drop_original:\n",
    "        dataset.drop(columns=[original_column], inplace=True)\n",
    "\n",
    "    if num_categories == 1:\n",
    "        dataset.drop(columns=[f\"{prefix}_no_1\"], inplace=True)\n",
    "        dataset.rename(columns={f\"{prefix}_no_1_binary\": f\"{prefix}\"}, inplace=True)\n",
    "    else:\n",
    "        for i in range(1, num_categories+1):\n",
    "            dataset.drop(columns=[f\"{prefix}_no_{i}\"], inplace=True)\n",
    "            dataset.rename(columns={f\"{prefix}_no_{i}_binary\": f\"{prefix}_{i}\"}, inplace=True)\n",
    "\n",
    "        if num_categories == 5:\n",
    "            dataset.rename(columns={f\"{prefix}_all_binary\": f\"{prefix}_all\"}, inplace=True)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04669cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd15c09",
   "metadata": {},
   "source": [
    "### 1.Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_title = len(df)\n",
    "col_pre_title = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d7750",
   "metadata": {},
   "source": [
    "#### 1.1Unqiue/ Dupclicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244489e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_values = df['Title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcbabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df.duplicated(['Title'], keep=False)].sort_values(by=['Title'])\n",
    "\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d874f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check it has been dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_title = len(df)\n",
    "col_post_title = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d634b",
   "metadata": {},
   "source": [
    "### 2.Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_rating = len(df)\n",
    "col_pre_rating = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46622b31",
   "metadata": {},
   "source": [
    "#### 2.1 Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping all rows that have missing values in the column Rating\n",
    "df = df.dropna(subset=['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quick check to see that the row was removed from the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4efcba8",
   "metadata": {},
   "source": [
    "#### 2.2 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values are between 0 and 10 (inclusive)\n",
    "column_values = df['Rating']\n",
    "count = column_values.between(0, 10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b67d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_rating = len(df)\n",
    "col_post_rating = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc68b96",
   "metadata": {},
   "source": [
    "### 3.Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_year = len(df)\n",
    "col_pre_year = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9301c30",
   "metadata": {},
   "source": [
    "#### 3.1 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values are between 0 and 10 (inclusive)\n",
    "column_values = df['Year']\n",
    "count = column_values.between(2002, 2023).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce656542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_year = len(df)\n",
    "col_post_year = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ebc71",
   "metadata": {},
   "source": [
    "### 4.Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ceb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_month = len(df)\n",
    "col_pre_month = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6787c99",
   "metadata": {},
   "source": [
    "#### 4.1 Unqiue values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a57851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all unique values in the column Month\n",
    "column_values = df['Month'].unique()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2932a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of values that aren't one of the 12 months\n",
    "count = sum(value not in ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                          'July', 'August', 'September', 'October', 'November', 'December']\n",
    "            for value in column_values)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc14ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the unwanted rows\n",
    "# List of valid months\n",
    "valid_months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "                'August', 'September', 'October', 'November', 'December']\n",
    "# Drop rows with invalid months from the original dataframe\n",
    "df.drop(index=df[~df['Month'].isin(valid_months)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92524e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that it has been dropped\n",
    "column_values = df['Month'].unique()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the rows have been dropped\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5002a679",
   "metadata": {},
   "source": [
    "#### 4.5 Converting row to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map months to integers\n",
    "month_to_int = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,\n",
    "                'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "\n",
    "# Apply the map() method to convert the values\n",
    "df['Month'] = df['Month'].map(month_to_int)\n",
    "\n",
    "# Convert the type of the column to int\n",
    "df['Month'] = df['Month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the month-values has been rplaced by 1-12 and the column converted to int\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values = df['Month'].unique()\n",
    "column_values.sort()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e815711",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_month = len(df)\n",
    "col_post_month = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407917e",
   "metadata": {},
   "source": [
    "### 5.Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48366d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_runtime = len(df)\n",
    "col_pre_runtime = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bdf4da",
   "metadata": {},
   "source": [
    "##### 5.1 Check non numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_non_numeric_values(df, \"Runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9114a",
   "metadata": {},
   "source": [
    "##### 5.2 Drop non numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Numbers' column to numeric values, converting non-numeric values to NaN\n",
    "df['Runtime'] = pd.to_numeric(df['Runtime'], errors='coerce')\n",
    "df = df.dropna(subset=['Runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee85269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the type has been changed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d6e70",
   "metadata": {},
   "source": [
    "#### 5.3 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f52678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many values are between 0 and 10 (inclusive)\n",
    "column_values = df['Runtime']\n",
    "count = column_values.between(30, 300).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6710f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fedd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_runtime = len(df)\n",
    "col_post_runtime = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1326d",
   "metadata": {},
   "source": [
    "### 7.Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_directors = len(df)\n",
    "col_pre_directors = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15b20b",
   "metadata": {},
   "source": [
    "#### 7.1 one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a46fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_directors = 2\n",
    "prefix_col = \"top_50_director\"\n",
    "df = one_hot_coding_binary(df, \"Directors\", prefix_col, \"Name\", \"C:/Users/admin1/Documents/GitHub/ds22_project/data/top_50_directors.csv\", num_categories=num_directors, drop_original=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print sum of each new column.\n",
    "sums = []\n",
    "for i in range(1, num_directors+1):\n",
    "    col_name = prefix_col + \"_\" + str(i)\n",
    "    if col_name in df.columns:\n",
    "        sums.append((col_name, df[col_name].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b863fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c94ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_directors = len(df)\n",
    "col_post_directors = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb9107",
   "metadata": {},
   "source": [
    "### 8.Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae155c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_stars = len(df)\n",
    "col_pre_stars = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ad135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b9021",
   "metadata": {},
   "source": [
    "#### 8.1 one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stars = 4\n",
    "prefix_col = \"top_1000_Stars\"\n",
    "df = one_hot_coding_binary(df, \"Stars\", prefix_col, \"Name\", \"C:/Users/admin1/Documents/GitHub/ds22_project/data/top_1000_actors.csv\", num_categories=num_stars, drop_original=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df38a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b14356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b56e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print sum of each new column.\n",
    "sums = []\n",
    "for i in range(1, num_stars+1):\n",
    "    col_name = prefix_col + \"_\" + str(i)\n",
    "    if col_name in df.columns:\n",
    "        sums.append((col_name, df[col_name].sum()))\n",
    "        \n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_stars = len(df)\n",
    "col_post_stars = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf218d8",
   "metadata": {},
   "source": [
    "### 9.Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_genre = len(df)\n",
    "col_pre_genre = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3fad32",
   "metadata": {},
   "source": [
    "#### 9.1 - one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_encoding_column(df, \"Genre\", prefix = \"genre_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking new dataset\n",
    "df.info()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ebb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_genre = len(df)\n",
    "col_post_genre = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dace6cd",
   "metadata": {},
   "source": [
    "### 10.Filming_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81296db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_filming_location = len(df)\n",
    "col_pre_filming_location = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc171c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3669ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 10.1 Unique Values\n",
    "column_values = df['Filming_location'].value_counts().sort_values(ascending=False)\n",
    "print(len(column_values))\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e903d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing 75 movies with Unknown filming_location. How can we replace them? and seeing 97 unique filming locations.\n",
    "#We we´re discussing if movies mostly are beeing done w/ green screen.\n",
    "#maybe remove the whole column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbace450",
   "metadata": {},
   "source": [
    "#### 10.2 - Drop the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Filming_location\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that it has been removed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_filming_location = len(df)\n",
    "col_post_filming_location = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267812b",
   "metadata": {},
   "source": [
    "### 11.Budget / 12.Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da60f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_budget = len(df)\n",
    "col_pre_budget = df.shape[1]\n",
    "rows_pre_income = len(df)\n",
    "col_pre_income = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41cd898",
   "metadata": {},
   "source": [
    "#### 1.1 convert to USD and strip of non numeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Budget'] = df['Budget'].apply(convert_to_usd)\n",
    "df['Income'] = df['Income'].apply(convert_to_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the change\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fcbb4e",
   "metadata": {},
   "source": [
    "#### 1.2 --- calc with inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5269bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adjust_for_inflation(df, \"Budget\", \"Year\", \"Budget_inf\", drop_original=True)\n",
    "df = adjust_for_inflation(df, \"Income\", \"Year\", \"Income_inf\", drop_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc8f103",
   "metadata": {},
   "source": [
    "#### 1.3 --- Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of rows in Budget > amount\n",
    "count = ((df['Budget_inf'] > 0) & (df['Budget_inf'] < 50000)).sum()\n",
    "print(count)\n",
    "filtered_df = df[(df['Budget_inf'] > 0) & (df['Budget_inf'] < 50000)]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows\n",
    "df.drop(filtered_df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of rows in Income < amount\n",
    "count = ((df['Income_inf'] > 0) & (df['Income_inf'] < 50000)).sum()\n",
    "print(count)\n",
    "filtered_df = df[(df['Income_inf'] > 0) & (df['Income_inf'] < 50000)]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows\n",
    "df.drop(filtered_df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e29fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the change\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b4118",
   "metadata": {},
   "source": [
    "### Notice -- The function to calculate inflation has turned all NaN into 0. (Had to be done to be able to calculate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa974fa0",
   "metadata": {},
   "source": [
    "#### 1.4 --- Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4edd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the missing values are 0 instead of NaN at this point (and 0 would also be treated like missing value )\n",
    "\n",
    "# count the number of occurrences of 0 in col1\n",
    "count_col1 = (df['Budget_inf'] == 0).sum()\n",
    "\n",
    "# count the number of occurrences of 0 in col2\n",
    "count_col2 = (df['Income_inf'] == 0).sum()\n",
    "\n",
    "# count the number of occurrences of 0 in both col1 and col2\n",
    "count_both = ((df['Budget_inf'] == 0) & (df['Income_inf'] == 0)).sum()\n",
    "\n",
    "# print the results\n",
    "print('Number of zeros in col1:', count_col1)\n",
    "print('Number of zeros in col2:', count_col2)\n",
    "print('Number of zeros in both col1 and col2:', count_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f2881",
   "metadata": {},
   "source": [
    "#### 1.5 --- Dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1227bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where both Budget_inf and Profit_inf are 0\n",
    "df = df[(df['Budget_inf'] != 0) | (df['Income_inf'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf4d0c",
   "metadata": {},
   "source": [
    "#### 1.6 --- Create Profit column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Profit_inf'] = df['Income_inf'] - df['Budget_inf']\n",
    "mask = (df['Income_inf'] == 0) | (df['Budget_inf'] == 0)\n",
    "df.loc[mask, 'Profit_inf'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f250b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef750830",
   "metadata": {},
   "source": [
    "#### 1.7 --- calculate mean profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e282272",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['Profit_inf'] > 0\n",
    "df_filtered = df[mask]\n",
    "mean_profit = df_filtered['Profit_inf'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3603a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3581fc9c",
   "metadata": {},
   "source": [
    "## Problem.... movies w/ income > $218M will get a negative budget.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36d65d",
   "metadata": {},
   "source": [
    "#### 1.8 --- Create ROI column and calculate mean_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e57484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ROI_inf'] = (df['Income_inf'] - df['Budget_inf']) / df['Income_inf']\n",
    "mask = (df['Income_inf'] == 0) | (df['Budget_inf'] == 0)\n",
    "df.loc[mask, 'ROI_inf'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc mean & median roi of the rows w/ values in both\n",
    "mask = df['ROI_inf'] != 0\n",
    "df_filtered = df[mask]\n",
    "mean_roi = df_filtered['ROI_inf'].mean()\n",
    "median_roi = df_filtered['ROI_inf'].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1fade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(median_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76101b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#why is mean roi negativ 200%? we´ll because some movies failed big and have big negative ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab883e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109db0e6",
   "metadata": {},
   "source": [
    "#### 1.9 -- replace 0 values in ROI_inf to median_ROI_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24556308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ROI_inf'] = df['ROI_inf'].replace(0, median_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0 and NaN values in the income_inf/budget_inf column with the median_roi\n",
    "df.loc[df['Income_inf'].isna() | (df['Income_inf'] == 0), 'Income_inf'] = df['Budget_inf'] * (1 + median_roi)\n",
    "df.loc[df['Budget_inf'].isna() | (df['Budget_inf'] == 0), 'Budget_inf'] = df['Income_inf'] / (1 + median_roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35856a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b66563",
   "metadata": {},
   "source": [
    "#### 1.10 --- update profit_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Profit_inf'] = df['Income_inf'] - df['Budget_inf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839dacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e117c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_budget = len(df)\n",
    "col_post_budget = df.shape[1]\n",
    "rows_post_income = len(df)\n",
    "col_post_income = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba9d4f",
   "metadata": {},
   "source": [
    "### 13.Country_of_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a823826",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_country_of_origin = len(df)\n",
    "col_pre_country_of_origin = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a67700",
   "metadata": {},
   "source": [
    "#### 13.1 --- Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_count = df['Country_of_origin'].str.split(', ').explode().value_counts()\n",
    "print(len(unique_values_count))\n",
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d8600",
   "metadata": {},
   "source": [
    "#### 13.2 Drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdcf77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Country_of_origin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f458ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check it has been dropped\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_country_of_origin = len(df)\n",
    "col_post_country_of_origin = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5573d8b4",
   "metadata": {},
   "source": [
    "## Certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a3fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pre_certificate = len(df)\n",
    "col_pre_certificate = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23798e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f36678",
   "metadata": {},
   "source": [
    "#### 1 --- Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df['Certificate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7893a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_count = df['Certificate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b192d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff4146",
   "metadata": {},
   "source": [
    "#### 1.2 --- Drop rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[(df['Certificate'].isnull()) | (df['Certificate'] == 'Not Rated') | (df['Certificate'] == 'Unrated')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_count_after_drop = df['Certificate'].value_counts()\n",
    "print(unique_values_count_after_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f48f10",
   "metadata": {},
   "source": [
    "#### 1.3 --- one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6164add",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_encoding_column(df, \"Certificate\", prefix = \"rated_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f95c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_post_certificate = len(df)\n",
    "col_post_certificate = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for display-porpuses at the end\n",
    "#headers = ['title', 'rating', 'year', 'month', 'runtime', 'directors', 'stars', 'genre', ]\n",
    "#rows_dropped = [0] * len(headers)\n",
    "\n",
    "#for i in range(len(headers)):\n",
    "#    pre_count = globals().get(f\"rows_pre_{headers[i]}\", 0)\n",
    "#    post_count = globals().get(f\"rows_post_{headers[i]}\", 0)\n",
    "#    rows_dropped[i] = pre_count - post_count\n",
    "#    print(f\"Rows dropped for {headers[i]}: {rows_dropped[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5962d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('movies_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd82723f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
